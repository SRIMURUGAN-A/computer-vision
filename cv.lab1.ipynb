{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python opencv-python-headless\n",
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74925bd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20241223::readNetFromDarknet'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load YOLO pre-trained weights and config files\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadNet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolov3.weights\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolov3.cfg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mgetLayerNames()\n\u001b[0;32m      7\u001b[0m output_layers \u001b[38;5;241m=\u001b[39m [layer_names[i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m net\u001b[38;5;241m.\u001b[39mgetLayers()]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20241223::readNetFromDarknet'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO pre-trained weights and config files\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getLayers()]\n",
    "\n",
    "# Load COCO class labels\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Open video file\n",
    "cap = cv2.VideoCapture('video_cv.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Get frame dimensions\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Prepare the frame for YOLO (resize, normalize, and create blob)\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(output_layers)\n",
    "\n",
    "    # Process the outputs to draw bounding boxes\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outputs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply Non-Maximum Suppression to reduce overlapping boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i], 2))\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label + \" \" + confidence, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1caa5456",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Detect faces in the frame\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mface_cascade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaleFactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminNeighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminSize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Draw rectangles around detected faces\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y, w, h) \u001b[38;5;129;01min\u001b[39;00m faces:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar Cascade Classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the video file (Replace 'video.mp4' with your video file path)\n",
    "video_path = r'C:\\Users\\AIDS_S00\\Downloads\\video_cv.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\") \n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break  # Exit the loop if the video ends\n",
    "\n",
    "    # Convert the frame to grayscale (Haar Cascade works with grayscale images)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw rectangles around detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with the detected faces\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Press 'q' to exit the loop and stop processing\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce0f20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original video dimensions: 3840x2160\n",
      "Resized video saved to: C:\\Users\\AIDS_S00\\Downloads\\resized_video.avi\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to your video\n",
    "video_path = r'C:\\Users\\AIDS_S00\\Downloads\\video_cv.mp4'\n",
    "\n",
    "# Check if the video file exists\n",
    "if not os.path.exists(video_path):\n",
    "    print(f\"Error: The file at {video_path} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get the original video width and height\n",
    "original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"Original video dimensions: {original_width}x{original_height}\")\n",
    "\n",
    "# Define the desired width and height for resizing the video\n",
    "resize_width = 640\n",
    "resize_height = 480\n",
    "\n",
    "# Create a VideoWriter object to save the resized video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec for saving the video (XVID, MJPG, etc.)\n",
    "output_path = r'C:\\Users\\AIDS_S00\\Downloads\\resized_video.avi'\n",
    "out = cv2.VideoWriter(output_path, fourcc, 30.0, (resize_width, resize_height))\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break  # Exit the loop if the video ends\n",
    "\n",
    "    # Resize the frame\n",
    "    frame = cv2.resize(frame, (resize_width, resize_height))\n",
    "\n",
    "    # Write the resized frame to the output video file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the resized frame (optional)\n",
    "    cv2.imshow('Resized Video', frame)\n",
    "\n",
    "    # Press 'q' to exit the loop and stop processing\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer objects and close all OpenCV windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Resized video saved to: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d99182ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original video dimensions: 3840x2160\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 40>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame_resized, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Detect faces in the frame\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mface_cascade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaleFactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminNeighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminSize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Draw rectangles around detected faces\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y, w, h) \u001b[38;5;129;01min\u001b[39;00m faces:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to your video\n",
    "video_path = r'C:\\Users\\AIDS_S00\\Downloads\\video_cv.mp4'\n",
    "\n",
    "# Check if the video file exists\n",
    "if not os.path.exists(video_path):\n",
    "    print(f\"Error: The file at {video_path} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get the original video width and height\n",
    "original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"Original video dimensions: {original_width}x{original_height}\")\n",
    "\n",
    "# Define the desired width and height for resizing the video\n",
    "resize_width = 640\n",
    "resize_height = 480\n",
    "\n",
    "# Load the pre-trained Haar Cascade Classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Create a VideoWriter object to save the resized video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec for saving the video (XVID, MJPG, etc.)\n",
    "output_path = r'C:\\Users\\AIDS_S00\\Downloads\\resized_video_with_faces.avi'\n",
    "out = cv2.VideoWriter(output_path, fourcc, 30.0, (resize_width, resize_height))\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break  # Exit the loop if the video ends\n",
    "\n",
    "    # Resize the frame to fit the screen\n",
    "    frame_resized = cv2.resize(frame, (resize_width, resize_height))\n",
    "\n",
    "    # Convert the resized frame to grayscale (Haar Cascade works with grayscale images)\n",
    "    gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw rectangles around detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame_resized, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Write the resized frame with face detection to the output video file\n",
    "    out.write(frame_resized)\n",
    "\n",
    "    # Display the resized frame with detected faces\n",
    "    cv2.imshow('Resized Video with Face Detection', frame_resized)\n",
    "\n",
    "    # Press 'q' to exit the loop and stop processing\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer objects and close all OpenCV windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Resized video with face detection saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a03abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original video dimensions: 3840x2160\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 47>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m blob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(frame_resized, \u001b[38;5;241m0.00392\u001b[39m, (resize_width, resize_height), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m, crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     57\u001b[0m yolo_net\u001b[38;5;241m.\u001b[39msetInput(blob)\n\u001b[1;32m---> 58\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[43myolo_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Process detections\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detection \u001b[38;5;129;01min\u001b[39;00m detections:\n",
      "\u001b[1;31merror\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to your video\n",
    "video_path = r'C:\\Users\\AIDS_S00\\Downloads\\video_cv.mp4'\n",
    "\n",
    "# Check if the video file exists\n",
    "if not os.path.exists(video_path):\n",
    "    print(f\"Error: The file at {video_path} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get the original video width and height\n",
    "original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"Original video dimensions: {original_width}x{original_height}\")\n",
    "\n",
    "# Define the desired width and height for resizing the video\n",
    "resize_width = 640\n",
    "resize_height = 480\n",
    "\n",
    "# Load YOLO object detection model\n",
    "yolo_net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = yolo_net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in yolo_net.getUnconnectedOutLayers()]\n",
    "\n",
    "\n",
    "# Load class labels\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Create a VideoWriter object to save the resized video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec for saving the video (XVID, MJPG, etc.)\n",
    "output_path = r'C:\\Users\\AIDS_S00\\Downloads\\resized_video_with_objects.avi'\n",
    "out = cv2.VideoWriter(output_path, fourcc, 30.0, (resize_width, resize_height))\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break  # Exit the loop if the video ends\n",
    "\n",
    "    # Resize the frame to fit the screen\n",
    "    frame_resized = cv2.resize(frame, (resize_width, resize_height))\n",
    "\n",
    "    # Convert frame to blob for YOLO object detection\n",
    "    blob = cv2.dnn.blobFromImage(frame_resized, 0.00392, (resize_width, resize_height), (0, 0, 0), True, crop=False)\n",
    "    yolo_net.setInput(blob)\n",
    "    detections = yolo_net.forward(output_layers)\n",
    "\n",
    "    # Process detections\n",
    "    for detection in detections:\n",
    "        for obj in detection:\n",
    "            scores = obj[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            # Filter weak detections\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(obj[0] * resize_width)\n",
    "                center_y = int(obj[1] * resize_height)\n",
    "                w = int(obj[2] * resize_width)\n",
    "                h = int(obj[3] * resize_height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # Draw rectangle and label\n",
    "                cv2.rectangle(frame_resized, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame_resized, f\"{classes[class_id]} {confidence:.2f}\", \n",
    "                            (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Write the resized frame with object detection to the output video file\n",
    "    out.write(frame_resized)\n",
    "\n",
    "    # Display the resized frame with object detection\n",
    "    cv2.imshow('Resized Video with Object Detection', frame_resized)\n",
    "\n",
    "    # Press 'q' to exit the loop and stop processing\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer objects and close all OpenCV windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Resized video with object detection saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd87b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original video dimensions: 3840x2160\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m blob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(frame_resized, \u001b[38;5;241m0.00392\u001b[39m, (resize_width, resize_height), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m, crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     59\u001b[0m yolo_net\u001b[38;5;241m.\u001b[39msetInput(blob)\n\u001b[1;32m---> 60\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[43myolo_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Process detections\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detection \u001b[38;5;129;01min\u001b[39;00m detections:\n",
      "\u001b[1;31merror\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Path to your video\n",
    "video_path = r'C:\\Users\\AIDS_S00\\Downloads\\video_cv.mp4'\n",
    "\n",
    "# Check if the video file exists\n",
    "if not os.path.exists(video_path):\n",
    "    print(f\"Error: The file at {video_path} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get the original video width and height\n",
    "original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"Original video dimensions: {original_width}x{original_height}\")\n",
    "\n",
    "# Define the desired width and height for resizing the video to a more manageable size for YOLO\n",
    "resize_width = 640\n",
    "resize_height = 480\n",
    "\n",
    "# Load YOLO object detection model\n",
    "yolo_net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = yolo_net.getLayerNames()\n",
    "\n",
    "# Get the output layers from YOLO\n",
    "output_layers = [layer_names[i - 1] for i in yolo_net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Load class labels\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Create a VideoWriter object to save the resized video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec for saving the video (XVID, MJPG, etc.)\n",
    "output_path = r'C:\\Users\\AIDS_S00\\Downloads\\resized_video_with_objects.avi'\n",
    "out = cv2.VideoWriter(output_path, fourcc, 30.0, (resize_width, resize_height))\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break  # Exit the loop if the video ends\n",
    "\n",
    "    # Resize the frame to fit the screen to reduce memory load\n",
    "    frame_resized = cv2.resize(frame, (resize_width, resize_height))\n",
    "\n",
    "    # Convert frame to blob for YOLO object detection\n",
    "    blob = cv2.dnn.blobFromImage(frame_resized, 0.00392, (resize_width, resize_height), (0, 0, 0), True, crop=False)\n",
    "    yolo_net.setInput(blob)\n",
    "    detections = yolo_net.forward(output_layers)\n",
    "\n",
    "    # Process detections\n",
    "    for detection in detections:\n",
    "        for obj in detection:\n",
    "            scores = obj[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            # Filter weak detections\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(obj[0] * resize_width)\n",
    "                center_y = int(obj[1] * resize_height)\n",
    "                w = int(obj[2] * resize_width)\n",
    "                h = int(obj[3] * resize_height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # Draw rectangle and label\n",
    "                cv2.rectangle(frame_resized, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame_resized, f\"{classes[class_id]} {confidence:.2f}\", \n",
    "                            (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Write the resized frame with object detection to the output video file\n",
    "    out.write(frame_resized)\n",
    "\n",
    "    # Display the resized frame with object detection\n",
    "    cv2.imshow('Resized Video with Object Detection', frame_resized)\n",
    "\n",
    "    # Press 'q' to exit the loop and stop processing\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer objects and close all OpenCV windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Resized video with object detection saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed93a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b256e7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original video dimensions: 3840x2160\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Path to your video\n",
    "video_path = r'C:\\Users\\AIDS_S00\\Downloads\\video_cv.mp4'\n",
    "\n",
    "# Check if the video file exists\n",
    "if not os.path.exists(video_path):\n",
    "    print(f\"Error: The file at {video_path} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get the original video width and height\n",
    "original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"Original video dimensions: {original_width}x{original_height}\")\n",
    "\n",
    "# Define the desired width and height for resizing the video to a more manageable size for YOLO\n",
    "resize_width = 320  # Must be divisible by 32\n",
    "resize_height = 320  # Must be divisible by 32\n",
    "\n",
    "# Load YOLO object detection model\n",
    "yolo_net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = yolo_net.getLayerNames()\n",
    "\n",
    "# Get the output layers from YOLO\n",
    "output_layers = [layer_names[i - 1] for i in yolo_net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Load class labels\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Create a VideoWriter object to save the resized video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec for saving the video (XVID, MJPG, etc.)\n",
    "output_path = r'C:\\Users\\AIDS_S00\\Downloads\\resized_video_with_objects.avi'\n",
    "out = cv2.VideoWriter(output_path, fourcc, 30.0, (resize_width, resize_height))\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break  # Exit the loop if the video ends\n",
    "\n",
    "    # Resize the frame to fit the screen to reduce memory load\n",
    "    frame_resized = cv2.resize(frame, (resize_width, resize_height))\n",
    "\n",
    "    # Convert frame to blob for YOLO object detection\n",
    "    blob = cv2.dnn.blobFromImage(frame_resized, 0.00392, (resize_width, resize_height), (0, 0, 0), True, crop=False)\n",
    "    yolo_net.setInput(blob)\n",
    "    detections = yolo_net.forward(output_layers)\n",
    "\n",
    "    # Process detections\n",
    "    for detection in detections:\n",
    "        for obj in detection:\n",
    "            scores = obj[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            # Filter weak detections\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(obj[0] * resize_width)\n",
    "                center_y = int(obj[1] * resize_height)\n",
    "                w = int(obj[2] * resize_width)\n",
    "                h = int(obj[3] * resize_height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # Draw rectangle and label\n",
    "                cv2.rectangle(frame_resized, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame_resized, f\"{classes[class_id]} {confidence:.2f}\", \n",
    "                            (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Write the resized frame with object detection to the output video file\n",
    "    out.write(frame_resized)\n",
    "\n",
    "    # Display the resized frame with object detection\n",
    "    cv2.imshow('Resized Video with Object Detection', frame_resized)\n",
    "\n",
    "    # Press 'q' to exit the loop and stop processing\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer objects and close all OpenCV windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Resized video with object detection saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c0230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd8363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "674e7496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\aids_s00\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\aids_s00\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\aids_s00\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\aids_s00\\anaconda3\\lib\\site-packages (from opencv-python-headless) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8d8740d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Load an image (replace 'image.jpg' with your image path)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m height, width, channels \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Convert image to blob for YOLO\u001b[39;00m\n\u001b[0;32m     18\u001b[0m blob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(img, \u001b[38;5;241m0.00392\u001b[39m, (\u001b[38;5;241m416\u001b[39m, \u001b[38;5;241m416\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m, crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO model\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Load COCO class labels\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Load an image (replace 'image.jpg' with your image path)\n",
    "img = cv2.imread('image.jpg')\n",
    "height, width, channels = img.shape\n",
    "\n",
    "# Convert image to blob for YOLO\n",
    "blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "# Process detections\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        \n",
    "        # Filter out weak detections\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            \n",
    "            # Rectangle coordinates\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            \n",
    "            # Draw rectangle and label\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(img, f\"{classes[class_id]} {confidence:.2f}\", (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with detections\n",
    "cv2.imshow('Image with Object Detection', img)\n",
    "\n",
    "# Wait for a key press and close the window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6588de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image processing is complete and saved!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load an Image\n",
    "image = cv2.imread('flower_img.jpg')  # Replace 'image.jpg' with your image file path\n",
    "\n",
    "# Check if the image is loaded correctly\n",
    "if image is None:\n",
    "    print(\"Error: Image not found.\")\n",
    "    exit()\n",
    "\n",
    "# 2. Convert Image to Grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 3. Resize the Image\n",
    "resize_width = 400\n",
    "resize_height = 400\n",
    "resized_image = cv2.resize(image, (resize_width, resize_height))\n",
    "\n",
    "# 4. Blur the Image (Gaussian Blur)\n",
    "blurred_image = cv2.GaussianBlur(image, (15, 15), 0)\n",
    "\n",
    "# 5. Apply Canny Edge Detection\n",
    "edges = cv2.Canny(gray_image, 100, 200)\n",
    "\n",
    "# 6. Display the Images\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Grayscale Image', gray_image)\n",
    "cv2.imshow('Resized Image', resized_image)\n",
    "cv2.imshow('Blurred Image', blurred_image)\n",
    "cv2.imshow('Edges', edges)\n",
    "\n",
    "# Wait for a key press and close all windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 7. Save the Processed Images (Optional)\n",
    "cv2.imwrite('grayscale_image.jpg', gray_image)\n",
    "cv2.imwrite('resized_image.jpg', resized_image)\n",
    "cv2.imwrite('blurred_image.jpg', blurred_image)\n",
    "cv2.imwrite('edges_image.jpg', edges)\n",
    "\n",
    "print(\"Image processing is complete and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40407da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f2a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a719a15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b0809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
